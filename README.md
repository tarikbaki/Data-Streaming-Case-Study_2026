# Trendyol Data Streaming Case â€“ Runbook

Bu dosya, case kapsamÄ±nda yaptÄ±ÄŸÄ±m tÃ¼m adÄ±mlarÄ±n uÃ§tan uca nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶zetler.  
AdÄ±mlarÄ± sade ve net biÃ§imde ilerlettim.

## Additional Reading
Kafka Ã¼zerine daha Ã¶nce yazdÄ±ÄŸÄ±m bir giriÅŸ yazÄ±sÄ±:

ðŸ‘‰ [What is Apache Kafka? â€“ Beginner Friendly Overview](https://medium.com/@tarikbaki/what-is-apache-kafka-a-beginner-friendly-overview-a32a04783ee3)


      Bu Ã§alÄ±ÅŸma, aws maliyet yaratmamak adÄ±na Terraform apply uygulanmadan hazÄ±rlanmÄ±ÅŸtÄ±r. TÃ¼m kaynak tanÄ±mlarÄ± eksiksizdir ve plan Ã§Ä±ktÄ±sÄ± Ã§alÄ±ÅŸÄ±r durumdadÄ±r. Request halinde apply yapÄ±lacak altyapÄ± hazÄ±rdÄ±r.
---
![alt text](docs/diag.png)


## 1) Terraform ile Infra HazÄ±rlÄ±ÄŸÄ±

- VPC oluÅŸturdum (10.20.0.0/16)
- 3 adet public subnet aÃ§tÄ±m (eu-central-1a, 1b, 1c)
- Internet Gateway + Route Table baÄŸladÄ±m
- Security Group oluÅŸturdum (challenge iÃ§in ÅŸimdilik tÃ¼m aÃ§Ä±k)
- Compute modÃ¼lÃ¼:
  - 4 broker node
  - 3 controller node
  - 1 connect node
  - 1 observability node
- Module outputsâ€™a gerekli IP'leri ekledim

### Komutlar

      cd terraform/envs/prod
      terraform init
      terraform apply

Ã§Ä±ktÄ±dan ipâ€™leri aldÄ±m. inventory scriptine ekleyip ansible iÃ§in hazÄ±rladÄ±m.

> Not: SG artÄ±k sadece gereken portlarÄ± aÃ§Ä±yor (22, 9092/9093, 9100, 5555/5556, 7777/7778, 8083/8084, 2020). Key olarak `challenge-key` bekliyor, user-data basit apt update yapÄ±yor. Backend S3 tanÄ±mlÄ±.

## 2) Ansible ile Kafka kurulumu (cp-ansible)

- inventory dosyasÄ±nÄ± terraform output ile doldurmak iÃ§in script yazdÄ±m
- cp-ansible requirements ekledim
- kafka broker ve controller rollerini playbookâ€™a koydum
- ayarlarÄ± group_vars/all.yml iÃ§ine yazdÄ±m

ansible-playbook -i ansible/inventory/hosts.ini ansible/playbooks/kafka.yml

> Not: `ansible/playbooks/certs.yml` self-signed keystore/truststore Ã¼retiyor (demo). GerÃ§ekte CA/vault ile deÄŸiÅŸtirmek lazÄ±m. Rack bilgisi inventoryâ€™den geliyor.

## 3) Observability

- prometheus iÃ§in skeleton dosyasÄ± bÄ±raktÄ±m
- alertmanager iskeleti koydum
- grafana klasÃ¶rÃ¼ aÃ§tÄ±m, dashboardlarÄ± sonra ekleyeceÄŸim
- hepsi observability ec2 Ã¼stÃ¼nde Ã§alÄ±ÅŸacak

## 4) Admin API

- flask ile api klasÃ¶rÃ¼ aÃ§tÄ±m
- dockerfile yazdÄ±m
- requirementlarÄ± ekledim
- ping endpoint ile baÅŸladÄ±m, sonra adminclient fonksiyonlarÄ±nÄ± koyacaÄŸÄ±m

## 5) Kafka Connect

- docker-compose ile connect nodeunu hazÄ±rladÄ±m
- http source plugin iÃ§in plugins klasÃ¶rÃ¼nÃ¼ oluÅŸturdum
- bootstrap ipâ€™yi sonra terraform outputâ€™tan alÄ±p compose iÃ§inde gÃ¼ncelleyeceÄŸim

## 6) Admin API (Flask + AdminClient)

- api klasorunu actim
- requirements.txt icine confluent-kafka ve flask ekledim
- dockerfile yazdim
- app.py icine brokers/topics/consumer-groups icin endpointleri koydum
- uygulama 2020 portunda calisiyor
- kafka baglantisini env ile yapiyorum:
  KAFKA_BOOTSTRAP_SERVERS="1.2.3.4:9092"

calistirmak icin:

      docker build -t admin-api .
      docker run -p 2020:2020 -e KAFKA_BOOTSTRAP_SERVERS="IP:9092" admin-api

## 7) Kafka Connect

- docker-compose ile connect nodeunu ayaga kaldirdim
- plugin klasoru actim (http source icin)
- connector config dosyasini ekledim (connect/config/http-source.json)

connector yaratma:

## 7) Kafka Connect

- docker-compose ile connect nodeunu ayaga kaldirdim
- plugin klasoru actim (http source icin)
- connector config dosyasini ekledim (connect/config/http-source.json)

connector yaratma:
      curl -X POST -H "Content-Type: application/json"
      --data @connect/config/http-source.json
      http://CONNECT_IP:8083/connectors


durum:
      curl http://CONNECT_IP:8083/connectors/http-source-1/status


listeleme:
      curl http://CONNECT_IP:8083/connectors


silme:
      curl -X DELETE http://CONNECT_IP:8083/connectors/http-source-1

## 8) Observability (Prometheus + Alertmanager + Grafana)

- observability ec2 uzerinde prometheus, alertmanager ve grafana calistiriyorum
- prometheus.yml baslangicta bos targetliydi
- terraform outputlarindan ip'leri alip prometheus dosyasina target olarak yazan script yazdim:

scripts/update_prometheus_targets.sh
      - node exporter butun ec2'lerde systemd servisi olarak calisacak
      - kafka broker ve controller icin jmx exporter portlarini ansible ile acacagim
      - connect icin de jmx portu expose edecegim

Prometheus baslatma:
            ./prometheus --config.file=prometheus.yml


Grafana baslatma:
            ./grafana-server


Alertmanager baslatma:
            ./alertmanager --config.file=alertmanager.yml

### Connector yaratma

      curl -X POST http://CONNECT_IP:8083/connectors
      -H "Content-Type: application/json"
      -d @connect/config/http-source.json


### Connector listeleme
      curl http://CONNECT_IP:8083/connectors


### Connector detay
      curl http://CONNECT_IP:8083/connectors/http-source-1


### Connector status
      curl http://CONNECT_IP:8083/connectors/http-source-1/status


### Connector tasks
      curl http://CONNECT_IP:8083/connectors/http-source-1/tasks

### Task status

      curl http://CONNECT_IP:8083/connectors/http-source-1/tasks/0/status

### Task restart

      curl -X POST http://CONNECT_IP:8083/connectors/http-source-1/tasks/0/restart


### Connector silme
      curl -X DELETE http://CONNECT_IP:8083/connectors/http-source-1

### Bootstrap server ipâ€™yi compose icine ekleme

      terraform output:
      terraform -chdir=terraform/envs/prod output broker_ips

ilk broker ipâ€™sini alÄ±yorum, Ã¶r:
      1.2.3.4

docker-compose.yml iÃ§inde:
      CONNECT_BOOTSTRAP_SERVERS="PLAINTEXT://1.2.3.4:9092"

### HÄ±zlÄ± test notlarÄ±
- Admin API:
  - `curl -X POST localhost:2020/topics -H "Content-Type: application/json" -d '{"name":"topic-1","num_partitions":3,"replication_factor":3}'`
  - `curl localhost:2020/brokers`, `curl localhost:2020/topics`, `curl localhost:2020/topics/topic-1`
  - `curl localhost:2020/consumer-groups`, `curl localhost:2020/consumer-groups/<group>`
- Connect:
  - `cd connect/docker && ./plugins/fetch_http_source.sh` (internet gerekir)
  - `docker-compose up -d`
  - `curl -X POST -H "Content-Type: application/json" --data @../config/http-source.json http://CONNECT_IP:8083/connectors`
  - `curl http://CONNECT_IP:8083/connectors/http-source-1/status`
- Prometheus targetlarÄ±nÄ± doldurmak:
  - `./scripts/update_prometheus_targets.sh` (Python kullanÄ±yor, sed farkÄ± yok)
  - `observability/prometheus/prometheus.yml` iÃ§inde jobâ€™lar otomatik yazÄ±lÄ±r
