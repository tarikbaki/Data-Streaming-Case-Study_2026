# Trendyol Data Streaming Case â€“ Runbook

Bu dosya, case kapsamÄ±nda yaptÄ±ÄŸÄ±m tÃ¼m adÄ±mlarÄ±n uÃ§tan uca nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶zetler.  
AdÄ±mlarÄ± sade ve net biÃ§imde ilerlettim.

Bonus: ## Additional Reading
Kafka Ã¼zerine daha Ã¶nce yazdÄ±ÄŸÄ±m bir giriÅŸ yazÄ±sÄ±:

ğŸ‘‰ [What is Apache Kafka? â€“ Beginner Friendly Overview](https://medium.com/@tarikbaki/what-is-apache-kafka-a-beginner-friendly-overview-a32a04783ee3)

---

## 1) Terraform ile Infra HazÄ±rlÄ±ÄŸÄ±

- VPC oluÅŸturdum (10.20.0.0/16)
- 3 adet public subnet aÃ§tÄ±m (eu-central-1a, 1b, 1c)
- Internet Gateway + Route Table baÄŸladÄ±m
- Security Group oluÅŸturdum (challenge iÃ§in ÅŸimdilik tÃ¼m aÃ§Ä±k)
- Compute modÃ¼lÃ¼:
  - 4 broker node
  - 3 controller node
  - 1 connect node
  - 1 observability node
- Module outputsâ€™a gerekli IP'leri ekledim

### Komutlar

    cd terraform/envs/prod
    terraform init
    terraform apply

Ã§Ä±ktÄ±dan ipâ€™leri aldÄ±m. inventory scriptine ekleyip ansible iÃ§in hazÄ±rladÄ±m.

## 2) Ansible ile Kafka kurulumu (cp-ansible)

- inventory dosyasÄ±nÄ± terraform output ile doldurmak iÃ§in script yazdÄ±m
- cp-ansible requirements ekledim
- kafka broker ve controller rollerini playbookâ€™a koydum
- ayarlarÄ± group_vars/all.yml iÃ§ine yazdÄ±m

ansible-playbook -i ansible/inventory/hosts.ini ansible/playbooks/kafka.yml

## 3) Observability

- prometheus iÃ§in skeleton dosyasÄ± bÄ±raktÄ±m
- alertmanager iskeleti koydum
- grafana klasÃ¶rÃ¼ aÃ§tÄ±m, dashboardlarÄ± sonra ekleyeceÄŸim
- hepsi observability ec2 Ã¼stÃ¼nde Ã§alÄ±ÅŸacak

## 4) Admin API

- flask ile api klasÃ¶rÃ¼ aÃ§tÄ±m
- dockerfile yazdÄ±m
- requirementlarÄ± ekledim
- ping endpoint ile baÅŸladÄ±m, sonra adminclient fonksiyonlarÄ±nÄ± koyacaÄŸÄ±m

## 5) Kafka Connect

- docker-compose ile connect nodeunu hazÄ±rladÄ±m
- http source plugin iÃ§in plugins klasÃ¶rÃ¼nÃ¼ oluÅŸturdum
- bootstrap ipâ€™yi sonra terraform outputâ€™tan alÄ±p compose iÃ§inde gÃ¼ncelleyeceÄŸim

## 6) Admin API (Flask + AdminClient)

- api klasorunu actim
- requirements.txt icine confluent-kafka ve flask ekledim
- dockerfile yazdim
- app.py icine brokers/topics/consumer-groups icin endpointleri koydum
- uygulama 2020 portunda calisiyor
- kafka baglantisini env ile yapiyorum:
  KAFKA_BOOTSTRAP_SERVERS="1.2.3.4:9092"

calistirmak icin:

    docker build -t admin-api .
    docker run -p 2020:2020 -e KAFKA_BOOTSTRAP_SERVERS="IP:9092" admin-api

## 7) Kafka Connect

- docker-compose ile connect nodeunu ayaga kaldirdim
- plugin klasoru actim (http source icin)
- connector config dosyasini ekledim (connect/config/http-source.json)

connector yaratma:
curl -X POST -H "Content-Type: application/json"
--data @connect/config/http-source.json
http://CONNECT_IP:8083/connectors


durum:
    ```bash
  curl http://CONNECT_IP:8083/connectors/http-source-1/status
    ```

listeleme:
      ```bash
curl http://CONNECT_IP:8083/connectors
    ```


silme:
    ```bash
curl -X DELETE http://CONNECT_IP:8083/connectors/http-source-1
    ```
    
## 8) Observability (Prometheus + Alertmanager + Grafana)

- observability ec2 uzerinde prometheus, alertmanager ve grafana calistiriyorum
- prometheus.yml baslangicta bos targetliydi
- terraform outputlarindan ip'leri alip prometheus dosyasina target olarak yazan script yazdim:

scripts/update_prometheus_targets.sh
- node exporter butun ec2'lerde systemd servisi olarak calisacak
- kafka broker ve controller icin jmx exporter portlarini ansible ile acacagim
- connect icin de jmx portu expose edecegim

Prometheus baslatma:
./prometheus --config.file=prometheus.yml


Grafana baslatma:
    ```bash
./grafana-server
    ```
    
Alertmanager baslatma:
    ```bash
./alertmanager --config.file=alertmanager.yml
    ```
    
### Connector yaratma

    ```
curl -X POST http://CONNECT_IP:8083/connectors
-H "Content-Type: application/json"
-d @connect/config/http-source.json
    ```

### Connector listeleme
    ```bash 
curl http://CONNECT_IP:8083/connectors 
       ```


### Connector detay

```curl http://CONNECT_IP:8083/connectors/http-source-1
```

### Connector status
```curl http://CONNECT_IP:8083/connectors/http-source-1/status
```

### Connector tasks
curl http://CONNECT_IP:8083/connectors/http-source-1/tasks

### Task status

```curl http://CONNECT_IP:8083/connectors/http-source-1/tasks/0/status
```
### Task restart
```
curl -X POST http://CONNECT_IP:8083/connectors/http-source-1/tasks/0/restart
```

### Connector silme
```curl -X DELETE http://CONNECT_IP:8083/connectors/http-source-1
```

### Bootstrap server ipâ€™yi compose icine ekleme

terraform output:
```
terraform -chdir=terraform/envs/prod output broker_ips

ilk broker ipâ€™sini alÄ±yorum, Ã¶r:
1.2.3.4
```
docker-compose.yml iÃ§inde:
```CONNECT_BOOTSTRAP_SERVERS="PLAINTEXT://1.2.3.4:9092"
```
## 9) Sertifika + keystore
- ansible/playbooks/certs.yml self-signed keystore/truststore oluÅŸturuyor, demo iÃ§in yeter.
- GerÃ§ekte CA/vault ile deÄŸiÅŸtirilmeli, parolalar vaultâ€™a taÅŸÄ±nmalÄ±.

## 10) HÄ±zlÄ± test
- Admin API:
- ```
  - curl -X POST localhost:2020/topics -H "Content-Type: application/json" -d '{"name":"topic-1","num_partitions":3,"replication_factor":3}'
  - curl localhost:2020/brokers
  - curl localhost:2020/topics
  - curl localhost:2020/topics/topic-1
  ```
- Connect:
- ```
  - cd connect/docker && ./plugins/fetch_http_source.sh (internet lazÄ±m)
  - docker-compose up -d
  - curl -X POST -H "Content-Type: application/json" --data @../config/http-source.json http://CONNECT_IP:8083/connectors
  - curl http://CONNECT_IP:8083/connectors/http-source-1/status
  ```
- Prometheus:
- ```
  - scripts/update_prometheus_targets.sh
  - prometheus.yml jobâ€™larÄ± doldurur, sonra prometheusâ€™u baÅŸlat
```
